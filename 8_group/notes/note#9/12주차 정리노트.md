# 12주차 정리노트

## 8조(김은미, 김승현)

---

### <10장. **케라스를 사용한 인공 신경망 소개>**

### 1. 인공 신경망(Artificial Neural Network)

- **뇌에 있는 생물학적 뉴런의 네트워크에서 영감을 받은 머신러닝 모델**
- 딥러닝의 핵심
- 강력, 확장성이 좋음
- 대규모 머신러닝 문제를 다루기에 적합함
    - 구글 이미지, 애플의 시리, 유튜브, 딥마인드의 알파고 등
- 다중 퍼셉트론(MLP, Multi-Layer Perceptron)

### 2. 퍼셉트론

- 가**장 간단한 인공 신경망 구조**로 1957년 프랑크 로젠블라트가 제안함
- 모든 입력은 가중치와 연결됨
- TLU 또는 LTU(linear threshold unit) 이라 불리는 인공 뉴런 활용
- **TLU(threshold logic unit)**
    - 입력값과 가중치를 곱한 값들의 합에 계단 함수(step function) 적용
- **퍼셉트론 정의**
    - 하나의 층에 여러 개의 TLU로 구성됨
    - TLU 각각은 모든 입력과 연결됨
    
- 퍼셉트론 학습 알고리즘
    - 오차가 감소되도록 가중치를 조절하며 뉴런 사이의 관계를 강화시킴
    - 하나의 샘플이 입력될 때마다 예측한 후에 오차를 계산하여 오차가 줄어드는 방향으로 가중치 조절
        
        ![스크린샷 2023-11-21 오후 2.13.50.png](12%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%E1%84%82%E1%85%A9%E1%84%90%E1%85%B3%20640f112e2c9d4c91ab094a2385433c3a/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7_2023-11-21_%25EC%2598%25A4%25ED%259B%2584_2.13.50.png)
        

- 퍼셉트론과 선형성
    - 각 출력 뉴런의 결정경계가 선형
    - 복잡한 패턴 학습 못함

### 3. 다층 퍼셉트론(multilayer perceptron, MLP)

- 퍼셉트론을 여러 개 쌓아올린 인공신경망
- 입력층 하나와 은닉층이라 불리는 하나 이상의 TLU층과 출력층으로 구성
- 모든 층은 편향을 포함하여, 다음 층과 완전히 연결되어 있음(fully connected)

![스크린샷 2023-11-21 오후 2.22.02.png](12%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%E1%84%82%E1%85%A9%E1%84%90%E1%85%B3%20640f112e2c9d4c91ab094a2385433c3a/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7_2023-11-21_%25EC%2598%25A4%25ED%259B%2584_2.22.02.png)

- 완전연결 층
    - 층에 속한 각각의 뉴런이 이전 층의 모든 뉴런과 연결되어 있을 때를 가리킴
    - 여러 개의 완전연결 층으로 구성된 다층 퍼셉트론 모델 계산
        
        ![스크린샷 2023-11-21 오후 2.58.15.png](12%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%E1%84%82%E1%85%A9%E1%84%90%E1%85%B3%20640f112e2c9d4c91ab094a2385433c3a/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7_2023-11-21_%25EC%2598%25A4%25ED%259B%2584_2.58.15.png)
        
    - 하나의 층에서 이루어지는 입력과 출력을 행렬 수식으로 표현 가능
        
        ![스크린샷 2023-11-21 오후 2.58.25.png](12%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%E1%84%82%E1%85%A9%E1%84%90%E1%85%B3%20640f112e2c9d4c91ab094a2385433c3a/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7_2023-11-21_%25EC%2598%25A4%25ED%259B%2584_2.58.25.png)
        

### 4. 분류를 위한 다층 퍼셉트론

- 이진 분류
    - 하나의 출력 뉴런 사용
    - 활성화 함수 : 로지스틱 함수
- 손실함수
    - 크로스 엔트로피

### 5. 케라스

- 모든 종류의 신경망을 손쉽게 만들어 주는 최상위 딥러닝 API 제공

**승현, 은미 : 케라스가 정확히 뭔지 잘 이해가 안됨…**

**추가로 찾아봄**

---

**케라스(Keras)는 파이썬으로 작성된 오픈 소스 신경망 라이브러리.**
텐서플로우, MXNet, Deeplearning4j 등을 백엔드로 사용하여 인공지능 코딩을 할 수 있게 해준다. 
딥 신경망을 빠르고 쉽게 코딩을 가능할 수 있게 해주고 최소한의 모듈 방식으로 확장 가능성에 초점을 둔 라이브러리이다. 사용하기 쉬운 고차원 딥러닝을 케라스 API를 통해 코딩을 할 수 있는데, 유저 친화적인 API를 제공하여 쉽게 딥러닝 모델을 만들어 낼 수 있어서 인공지능 코딩에 현재 가장 많이 사용되고 있는 라이브러리 이다.

- **케라스의 구조**

![Untitled](12%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%E1%84%82%E1%85%A9%E1%84%90%E1%85%B3%20640f112e2c9d4c91ab094a2385433c3a/Untitled.png)

텐서플로우, CNTK, Theano, MXNet등을 백엔드로 하여 각 라이브러리를 쉽게 사용할 수 있게 하면서 안정화도 시켜주는 역할을 케라스가 한다.

- **케라스의 장점**
    - **사용자 친화적** 
    케라스는 일반 사용 사례에 최적화된 간단하고 일관적인 인터페이스를 제공합니다. 이는 사용자 오류에 대해 명확하고 실용적인 피드백을 제공한다.
    - **모듈화 및 구성 가능성**
    케라스 모델은 구성 요소의 설정에 의해 연결되는 식으로 거의 제한없이 만들 수 있다.
    - **쉬운 확장**
    연구를 위한 새로운 아이디어를 표현하기 위해 사용자 정의 설계 블록을 작성하면, 
    새로운 층(layers), 지표(metrics), 손실 함수를 생성하고 최첨단 모델을 개발할 수 있다.

### 6. 콜백함수

- **체크포인트(checkpoint)** 저장시 사용
    - 대규모 데이터셋에서 훈련 시에 훈련 도중 일정 간격으로 체크포인트를 저장해야 함
    - **콜백함수**를 이용하여 지정 가능