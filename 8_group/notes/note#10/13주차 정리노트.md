# 13주차 정리노트

## 8조(김은미, 김승현)

---

### <14장. **합성곱 신경망을 사용한 컴퓨터 비전>**

### 1. 시각 피질 구조

- 합성곱 신경망(CNN)은 대뇌 시각 피질 연구에서 시작
- 국부수용장(local receptive) 모델을 모방
- **합성곱신경망(CNN)**으로 발전
    - 합성곱 층(convolution layer), 풀링 층(pooling layer)

**+) 추가로 찾아본 CNN에 대하여**

- 인간의 시신경 구조를 모방한 기술
- 이미지를 인식하기 위해 패턴을 찾는데 특히 유용함
- 사람이 여러 데이터를 보고 기억한 후에 무엇인지 맞추는 것과 유사함
- 데이터를 직접 학습하고 패턴을 사용해 이미지를 분류함

### 2. 합성곱 층

- **CNN의 가장 중요한 구성 요소는 합성곱 층**
- 첫 번째 합성곱 층의 뉴런은 입력 이미지의 모든 픽셀에 연결되는 것이 아니라
합성곱 층 뉴런의 수용장 안에 있는 픽셀에만 연결
- 두 번째 합성곱 층에 있는 각 뉴런은 첫 번째 층의 작은 사각 영역 안에 위치한 뉴런에 연결
- **스트라이드(보폭, stride) : 한 수용장과 다음 수용장 사이의 간격**

### 3. 필터 (합성곱 커널)

- 입력뉴런에 사용될 가중치 역할 수행
- 필터의 모양, 크기가 국부수용장의 모양과 크기를 지정함
- 다양한 필터 사용

### 4. 풀링 층

- 계산량과 메모리 사용량을 줄이면서 과대적합의 위험도를 줄여주는 용도로 사용됨
- 풀링 층 뉴런은 가중치가 없음
- 스트라이드(보폭, stride)를 사용하여 차원을 축소시키는 기능 수행
- **최대 풀링 층(max pooling layer)**
    - 특징 
    1. 파라미터 수를 획기적으로 줄여 계산량, 메모리 사용량을 줄어줌.
    2. 많은 정보를 잃게 되지만 그대로 잘 작동함 **→ ? 정보를 잃게되는데 쓸 이유가 뭔?**
    3. 작은 변화에 대한 어느 정도의 불변성 보장됨

### 5. CNN 구조

- **전형적인 CNN 구조**
    - 네트워크를 통과하여 진행할수록 이미지는 점점 작아지지만,
    합성곱 층 때문에 일반적으로 점점 더 깊어짐 **⇒ 즉, 더 많은 특성 맵을 가지게 됨**
    - 이미지 인식 문제에서 완전 연결 층의 심층 신경망을 사용하지 않는 이유 **⇒ 파라미터가 너무 많아짐**
    - 합성곱 층에 사용하는 커널 크기
        - 작은 커널이 파라미터와 계산량이 적고 일반적으로 더 나은 성능을 냄
            
            <img width="661" alt="1" src="https://github.com/seunghyuniisme/ML/assets/145260996/3bb67ebe-ff14-47a8-be79-ef32e030f31c">            

참고 사이트
[https://rubber-tree.tistory.com/entry/딥러닝-모델-CNN-Convolutional-Neural-Network-설명](https://rubber-tree.tistory.com/entry/딥러닝-모델-CNN-Convolutional-Neural-Network-설명)
