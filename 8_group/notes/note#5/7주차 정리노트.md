# 7주차 정리노트

[https://di-bigdata-study.tistory.com/2](https://di-bigdata-study.tistory.com/2)

결정 트리

- 분류, 회귀, 다중출력 작업이 가능한 머신러닝 알고리즘
- 랜덤 포레스트의 기본 구성 요소

gini : 해당 노드의 불순도 측정값

- gini 값이 높을 수록 잘 분류되지 못한 것
- gini 값이 0이면 순수?

## 6.10 연습 문제(정답 확실 X)

### 다음 단계에 따라 moons 데이터셋에 결정트리를 훈련시키고 세밀하게 튜닝하라

![Untitled](7%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%E1%84%82%E1%85%A9%E1%84%90%E1%85%B3%20cbeea7af9bc649bbb9fe614abd79a626/Untitled.png)

1. **make_moons(n_sample=1000, noise=0.4)를 사용해 데이터셋을 생성한다.**

![Untitled](7%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%E1%84%82%E1%85%A9%E1%84%90%E1%85%B3%20cbeea7af9bc649bbb9fe614abd79a626/Untitled%201.png)

- make_moons 는 정확하게 뭔지?
    - 분류용 가상 데이터를 생성하는 함수 중 하나
    - 초승달 모양 클러스터 두 개 형상의 데이터를 생성한다.
    - `make_moons` 명령으로 만든 데이터는 직선을 사용하여 분류할 수 없다.
- 인수 :
    - `n_samples` : 표본 데이터의 수, 디폴트 100
    - `noise`: 잡음의 크기. 0이면 정확한 반원을 이룸
    

1. **이를 train_test_split()응 사용해 훈련 세트와 테스트 세트로 나눈다.**

![Untitled](7%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%E1%84%82%E1%85%A9%E1%84%90%E1%85%B3%20cbeea7af9bc649bbb9fe614abd79a626/Untitled%202.png)

- train_test_split() 함수
    - 데이터셋을 테스트 데이터와 훈련 데이터로 분류해준다.
    - test_size 인수는? : 훈련, 테스트 데이터의 비율을 결정함 ( 0.2 ?)
    - random_state에 값을 입력하지 않으면 랜덤한 선택으로 데이터 값을 분류한다.
    특정 수(위에서는 42)로 결정하면 Seed 값이 동일해서 동일한 방식으로 데이터를 분류해준다.
    

1. **DecisionTreeClassifier의 최적의 매개변수를 찾기 위해 교차 검증과 함께 그리드 탐색을 수행한다.  (GridSearchCV를 사용하면 됨. 여러가지 max_leaf_nodes 값을 시도)**

![Untitled](7%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%E1%84%82%E1%85%A9%E1%84%90%E1%85%B3%20cbeea7af9bc649bbb9fe614abd79a626/Untitled%203.png)

1. **찾은 매개 변수를 사용해 전체 훈련 세트에 대해 모델을 훈련시키고 테스트 세트에서 성능을 측정한다.** 

![Untitled](7%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%E1%84%82%E1%85%A9%E1%84%90%E1%85%B3%20cbeea7af9bc649bbb9fe614abd79a626/Untitled%204.png)

흠..