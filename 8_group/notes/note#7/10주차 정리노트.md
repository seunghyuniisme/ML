# 10주차 정리노트

## 8조 (김은미, 김승현)

---

### <8장. 차원축소>

[](https://github.com/rickiepark/handson-ml2/blob/master/08_dimensionality_reduction.ipynb)

### 1. 차원 축소

- 특성 수를 줄여서 학습 불가능한 문제를 학습 가능한 문제로 만드는 기법.
- 훈련 속도가 빨라지지만, 일부 정보가 유실되어 성능이 저하 될수 있음.

### 2. 차원 축소를 위한 접근 방법

- 투영(Projection)
    - 𝑛차원 공간에 존재하는 𝑑차원 부분공간을 𝑑차원 공간으로 투영하기. (단, 𝑑 < 𝑛)
    - 차원 축소에 있어서 투영이 언제나 최선의 방법은 아님.
    - 개선해서 나온게 매니폴드 학습?

- 매니폴드 학습
    - d 차원 매니폴드는 국부적으로 d 차원 초평면으로 보일 수 있는 n 차원 공간의 일부 (d<n)

### 3. PCA

- Principal Component Analysis
- 주성분 분석은 먼저 데이터에 가장 가까운 초평면을 정의한 다음, 데이터를 이 평면에 투영시킴.

- PCA 좀 더 자세히 (어려워서..)
    - 차원 축소와 변수 추출 기법으로 널리 쓰이고 있다.
    - 주성분이란 전체 데이터(독립변수들)의 분산을 가장 잘 설명하는 성분을 말한다.
    - 변수의 개수 = 차원의 개수
    - 예를 들어서 iris 데이터에서, 4개의 독립변인들이 하나의 공간에 표현되기 위해서는, 공간이 4차원이어야 한다. → 차원이 증가할수록 데이터가 표현해야 하는 공간은 복잡해진다.
    - ⇒ 변수가 너무 많아 기존 변수를 조합해 새로운 변수를 가지고 모델링을 하려고 할 때 주로 PCA를 사용한다. (이 때, 중요함의 기준은 전체 데이터(독립변수들, 모든 차원)의 변산을 얼마나 잘 설명하는가에 있다.)
    - 참고 : [https://velog.io/@swan9405/PCA](https://velog.io/@swan9405/PCA)
    

### 4. 분산 보존

- 저차원으로 투영할 때 훈련 세트의 분산이 최대로 보존되는 축을 선택해야 함.
- 분산이 최대로 보존되어야 정보가 가장 적게 손실됨.
- **원본 데이터셋과 투영된 데이터셋 사이의 평균제곱거리 최소화하는 축 선택**

- **실습 코드 8-8 적절한 차원수 선택하기 코드 자세히 알아두기(기말)
<그림 8-8. 차원 수에 대한 함수로 나타낸 설명된 분산> 생성 코드**

<img width="285" alt="스크린샷 2023-11-11 오후 2 54 38" src="https://github.com/seunghyuniisme/ML/assets/145260996/a5ce25d7-9d06-4771-8020-4e5f7cec5245">
